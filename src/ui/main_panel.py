import streamlit as st
import time
from src.backend.model_engine import execute_pipeline

def render_main_panel(db_instance, config, logo_img=None):
    
    # --- 0. L√ìGICA DE RESET (SOLUCI√ìN AL ERROR) ---
    # Verificamos si hay una petici√≥n de limpieza pendiente ANTES de pintar nada
    if st.session_state.get("trigger_input_reset"):
        st.session_state["topic_pill_selection"] = None
        st.session_state["topic_input_field"] = "General"
        st.session_state["trigger_input_reset"] = False # Apagamos la bandera

    # --- Header ---
    c1, c2 = st.columns([1, 5])
    with c1:
        if logo_img:
            st.image(logo_img, width=80)
        else:
            st.write("ü§ñ")
    with c2:
        st.title("pItAgorin")
        st.caption("Orchestrating the Wisdom of AI")

    # --- Knowledge Ingestion Section ---
    with st.expander("üìö Feed Knowledge Base (Upload Data)", expanded=False):
        
        tab_manual, tab_upload = st.tabs(["‚úçÔ∏è Manual Text", "üìÅ Upload File"])
        content_to_save = ""
        source_name = "manual"
        
        with tab_manual:
            manual_text = st.text_area("Paste text content here:", height=150)
            
        with tab_upload:
            uploaded_file = st.file_uploader("Upload a document", type=["txt", "md"])

        # --- L√ìGICA DE SELECCI√ìN UNIFICADA ---
        st.write("---")
        
        def _update_text_from_pill():
            if st.session_state.get("topic_pill_selection"):
                st.session_state["topic_input_field"] = st.session_state["topic_pill_selection"]

        col_input, col_btn = st.columns([4, 1])
        
        with col_input:
            topic_tag = st.text_input(
                "Topic / Tag", 
                value="General", 
                key="topic_input_field",
                placeholder="Type new or select below..."
            )
            
            existing_topics = db_instance.get_topics()
            if existing_topics:
                st.caption("Quick Select Existing:")
                st.pills(
                    "Existing Topics",
                    options=existing_topics,
                    label_visibility="collapsed",
                    key="topic_pill_selection",
                    on_change=_update_text_from_pill,
                    selection_mode="single"
                )
        
        with col_btn:
            st.write("") 
            save_btn = st.button("üíæ Save", use_container_width=True)

        # --- Saving Logic ---
        if save_btn:
            if uploaded_file:
                try:
                    content_to_save = uploaded_file.getvalue().decode("utf-8")
                    source_name = uploaded_file.name
                except Exception as e:
                    st.error(f"Error: {e}")
            elif manual_text.strip():
                content_to_save = manual_text
                source_name = "manual_input"

            if content_to_save:
                db_instance.add_document(content_to_save, topic_tag, source_name)
                st.success(f"‚úÖ Added to **{topic_tag}**")
                
                # --- AQU√ç EST√Å EL CAMBIO CLAVE ---
                # En lugar de limpiar directamente, activamos la bandera y recargamos
                st.session_state["trigger_input_reset"] = True
                time.sleep(0.5)
                st.rerun()
            else:
                st.warning("‚ö†Ô∏è Provide text first.")

    st.divider()

    # --- WORKSPACE ---
    st.subheader("Workspace")
    user_prompt = st.text_area("Enter your main instruction/prompt:", height=100)

    with st.expander("‚öôÔ∏è Advanced Prompt Engineering", expanded=False):
        c1, c2 = st.columns(2)
        with c1:
            role = st.text_input("üé≠ Role / Persona")
            audience = st.text_input("üéØ Target Audience")
            tone = st.selectbox("üé® Tone & Style", ["Default", "Formal", "Concise", "Creative", "Socratic", "ELI5"])
        with c2:
            output_format = st.selectbox("üìù Output Format", ["Text", "Markdown Table", "Bullet Points", "JSON", "Code"])
            structure_override = st.text_input("Custom structure:")
            active_constraints = st.multiselect("üö´ Negative Constraints", ["No preambles", "No apologies", "No passive voice", "No jargon"])
            negative_context = st.text_input("Specific Avoidance")

    if st.button("üöÄ Execute Pipeline", type="primary"):
        if not config.get("pipeline_steps"):
            st.error("Sidebar config required.")
            return
        if not user_prompt:
            st.warning("Main prompt required.")
            return

        system_instruction = []
        if role: system_instruction.append(f"ROLE: Act as a {role}.")
        if audience: system_instruction.append(f"AUDIENCE: Adapt response for {audience}.")
        if tone and tone != "Default": system_instruction.append(f"TONE: {tone}.")
        
        final_format = structure_override if structure_override else output_format
        if final_format != "Text": system_instruction.append(f"FORMAT: Provide output as {final_format}.")
        
        all_constraints = active_constraints.copy()
        if negative_context: all_constraints.append(negative_context)
        if all_constraints: system_instruction.append(f"CONSTRAINTS: {', '.join(all_constraints)}.")

        meta_prompt = "\n".join(system_instruction)
        temas_seleccionados = config.get("rag_topics", []) 
        retrieved_context = db_instance.query_db(user_prompt, temas_seleccionados)
        
        full_input_package = ""
        if meta_prompt: full_input_package += f"--- SYSTEM INSTRUCTIONS ---\n{meta_prompt}\n\n"
        if retrieved_context:
            st.info(f"üí° RAG Active: {len(temas_seleccionados)} topics.")
            full_input_package += f"--- KNOWLEDGE BASE CONTEXT ---\n{retrieved_context}\n\n"
        full_input_package += f"--- TASK ---\n{user_prompt}"

        current_input = full_input_package
        
        with st.status("Processing Pipeline...", expanded=True) as status:
            pipeline_steps = config.get("pipeline_steps", [])
            for i, step in enumerate(pipeline_steps):
                status.write(f"‚ñ∂Ô∏è **Step {i+1}:** Running {step['model_id']}...")
                try:
                    output = execute_pipeline(step, current_input)
                    st.markdown(f"**Output Step {i+1} ({step['task']}):**")
                    st.success(output)
                    current_input = output
                except Exception as e:
                    st.error(f"Error in step {i+1}: {str(e)}")
                    status.update(label="Execution Failed", state="error")
                    return
            status.update(label="Pipeline Completed!", state="complete", expanded=False)